{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8536624f",
   "metadata": {},
   "source": [
    "# Getting the securities lending open positions from the brazilian stock exchange\n",
    "\n",
    "**What ?** Securities lending open positions refer to the active loans in which securities, such as stocks or bonds, have been lent by one party (the lender) to another (the borrower) in exchange for collateral. These open positions indicate that the borrower has temporary possession of the securities and has yet to return them to the lender. The Brazilian stock exchange, B3, provides daily data on all open positions, including quantities, volumes, and average prices, grouped by ticker and type of register [[see glossary here]](https://www.b3.com.br/data/files/BF/F1/58/15/391EA810E9C1AAA8AC094EA8/Glossario%20_%20Posicao_Em_Aberto.pdf).\n",
    "\n",
    "**Why ?** Securities lending open positions data is crucial for financial market analysis related on market sentiment indicator, supply and demand insights, risk management and price movement predictions.\n",
    "\n",
    "**How ?** The open position data is available in a comprehensive PDF document titled [Daily Market Bulletin](https://www.b3.com.br/pt_br/market-data-e-indices/servicos-de-dados/market-data/consultas/boletim-diario/boletim-diario-do-mercado/), which spans over one hundred pages and includes various unstructured market data. To extract the open position tables, the PDF documents were manually downloaded from the B3 website. A complex scraping code was then developed using the **pdfplumber** Python library to parse the textual data and convert it into a structured dataframe. Finally, the dataframe is saved into a local SQLite database for further analysis.\n",
    "\n",
    "<img src=\"https://lh3.googleusercontent.com/d/1hHJx0qCjbFOMg4hjF7CK7dEei-xUPaNF\" alt=\"securities_lending_open_position_icon\" width=\"300\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385c243b",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac5a5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "import sqlite3\n",
    "import requests\n",
    "import zipfile\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da35bf77",
   "metadata": {},
   "source": [
    "# Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d5a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_directory = os.getcwd() #getting the script directory path\n",
    "directory_path = os.path.join(script_directory,'temp_file') # Define the file path within the subfolder\n",
    "initial_tag = 'Empréstimos de Ativos – Posição em Aberto' # string phrase that marks the beginning of the table\n",
    "final_tag = 'Empréstimos de Ativos – Empréstimos Registrados' # string phrase that marks the end of the table\n",
    "initial_word_tag = 'Aberto' \n",
    "final_word_tag = 'Registrados'\n",
    "table_columns = ['Data_dt','Ticker','ISIN','empresa_oufundo','Tipo','Mercado','saldo_qte','preco_medio','saldo_volfin'] #columns to be extracted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ace547",
   "metadata": {},
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e3cd06",
   "metadata": {},
   "source": [
    "### Extracting downloaded pdf file name list to be scrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8060cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_get_file_names(directory_path):\n",
    "    pattern = re.compile(r'^BDI_00_\\d{8}.pdf$') # daily bulletin pattern name\n",
    "    matching_files = [f for f in os.listdir(directory_path) if pattern.match(f)]\n",
    "    return matching_files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ced65d",
   "metadata": {},
   "source": [
    "### Find initial and final pages of the table by the tag's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dcbadf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_find_string_in_pdf(pdf_path, search_string):\n",
    "    # Open the PDF file\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    pages_with_string = []\n",
    "    # Iterate through each page\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text = page.get_text()\n",
    "\n",
    "        # Check if the search string is in the text of the current page\n",
    "        if search_string in text:\n",
    "            pages_with_string.append(page_num + 1)  # Pages are 1-indexed\n",
    "    \n",
    "    if not pages_with_string:\n",
    "        print(\"\\n\\n**** The tag phrase was not fount in this document! ****\\n\\n\")\n",
    "        return\n",
    "    else: \n",
    "        return pages_with_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6454265",
   "metadata": {},
   "source": [
    "### Getting the table from the page range and parsing data into a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61286e2b",
   "metadata": {},
   "source": [
    "##### Hey, this was a very hard function to build, send me a message on [linkedin](https://www.linkedin.com/in/lucas-aragao-santos/) and I will be glad to share with you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd31478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions import func_btb_open_pos_extract_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eba779b",
   "metadata": {},
   "source": [
    "###  Processing and cleaning the table scrapped into a final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a4bde8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def func_clean_and_convert_to_float(value):\n",
    "    try:\n",
    "        # Remove leading and trailing whitespaces\n",
    "        cleaned_value = value.strip()\n",
    "        # Remove any internal white spaces\n",
    "        cleaned_value = cleaned_value.replace(' ', '')  \n",
    "        # Check if the cleaned value is a valid float\n",
    "        if re.match(r'^-?\\d+(\\.\\d+)?$', cleaned_value):\n",
    "            return float(cleaned_value)\n",
    "        else:\n",
    "            # Handle cases where the value is not a valid float\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        # Handle unexpected errors\n",
    "        return None\n",
    "\n",
    "\n",
    "def func_process_dataframe(df):\n",
    "    \n",
    "    df.replace({'-': np.nan, '': np.nan}, inplace=True) # normalizing null valus\n",
    "    df.dropna(subset=['Ticker'], inplace = True) # drop lines where there is no usefull information\n",
    "    # changing data types \n",
    "    df['saldo_qte'] = df['saldo_qte'].str.replace('.', '', regex=False)\n",
    "    df['preco_medio'] = df['preco_medio'].str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
    "    df['saldo_volfin'] = df['saldo_volfin'].str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
    "    \n",
    "    df['saldo_qte'] = df['saldo_qte'].apply(func_clean_and_convert_to_float)\n",
    "    df['preco_medio'] = df['preco_medio'].apply(func_clean_and_convert_to_float)\n",
    "    df['saldo_volfin'] = df['saldo_volfin'].apply(func_clean_and_convert_to_float)\n",
    "    \n",
    "    \n",
    "    # remapping class values tha was not well scrapped\n",
    "    df['Mercado'] = df['Mercado'].str.replace('NDe+1g. Eletrônica', 'Neg. Eletrônica/D+1', regex=False)\n",
    "    df['Mercado'] = df['Mercado'].str.replace('NDe+0g. Eletrônica', 'Neg. Eletrônica/D+0', regex=False)\n",
    "    # adding a processing data column to referece the date of the scraping process run\n",
    "    df['proc_datedt'] = datetime.now().replace(microsecond=0) \n",
    "\n",
    "    print('Dataframe was processed and cleaned ...')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c8a86d",
   "metadata": {},
   "source": [
    "## Calling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac1c8f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- Extracting from file: BDI_00_20240102.pdf ----------------------\n",
      "\n",
      "The string \"Empréstimos de Ativos – Posição em Aberto\" was last found on the following page: 567 \n",
      "\n",
      "The string \"Empréstimos de Ativos – Empréstimos Registrados\" was last found on the following page: 595 \n",
      "\n",
      "\n",
      "--------------- Step 1 completed ----------------\n",
      "\n",
      "Starting scrapping tables from page ...\n",
      "567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 \n",
      "--------------- Step 2 completed ----------------\n",
      "\n",
      "Dataframe was processed and cleaned ...\n",
      "\n",
      "--------------- Step 3 completed ----------------\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1488 entries, 0 to 1487\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   Data_dt          1488 non-null   object        \n",
      " 1   Ticker           1488 non-null   object        \n",
      " 2   ISIN             1488 non-null   object        \n",
      " 3   empresa_oufundo  1488 non-null   object        \n",
      " 4   Tipo             1488 non-null   object        \n",
      " 5   Mercado          1488 non-null   object        \n",
      " 6   saldo_qte        1488 non-null   float64       \n",
      " 7   preco_medio      1488 non-null   float64       \n",
      " 8   saldo_volfin     1488 non-null   float64       \n",
      " 9   doc_page         1488 non-null   int64         \n",
      " 10  proc_datedt      1488 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(6)\n",
      "memory usage: 128.0+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_dt</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>ISIN</th>\n",
       "      <th>empresa_oufundo</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Mercado</th>\n",
       "      <th>saldo_qte</th>\n",
       "      <th>preco_medio</th>\n",
       "      <th>saldo_volfin</th>\n",
       "      <th>doc_page</th>\n",
       "      <th>proc_datedt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02/01/2024</td>\n",
       "      <td>5GTK11</td>\n",
       "      <td>BR5GTKCTF000</td>\n",
       "      <td>IÍNNVDEICSET OIE ETF BLUESTAR 5G COM INDEX FDO</td>\n",
       "      <td>CI</td>\n",
       "      <td>Registro</td>\n",
       "      <td>1.00</td>\n",
       "      <td>81.82</td>\n",
       "      <td>81.82</td>\n",
       "      <td>567</td>\n",
       "      <td>2024-06-21 08:20:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02/01/2024</td>\n",
       "      <td>A1CR34</td>\n",
       "      <td>BRA1CRBDR003</td>\n",
       "      <td>AMCOR PLC</td>\n",
       "      <td>DRN</td>\n",
       "      <td>Registro</td>\n",
       "      <td>17.00</td>\n",
       "      <td>47.19</td>\n",
       "      <td>802.30</td>\n",
       "      <td>567</td>\n",
       "      <td>2024-06-21 08:20:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02/01/2024</td>\n",
       "      <td>A1DM34</td>\n",
       "      <td>BRA1DMBDR002</td>\n",
       "      <td>ARCHER-DANIELS-MIDLAND CO</td>\n",
       "      <td>DRN</td>\n",
       "      <td>Registro</td>\n",
       "      <td>102.00</td>\n",
       "      <td>354.03</td>\n",
       "      <td>36111.06</td>\n",
       "      <td>567</td>\n",
       "      <td>2024-06-21 08:20:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02/01/2024</td>\n",
       "      <td>A1EP34</td>\n",
       "      <td>BRA1EPBDR003</td>\n",
       "      <td>AMERICAN ELECTRIC POWER CO INC</td>\n",
       "      <td>DRN</td>\n",
       "      <td>Registro</td>\n",
       "      <td>6.00</td>\n",
       "      <td>195.27</td>\n",
       "      <td>1171.62</td>\n",
       "      <td>567</td>\n",
       "      <td>2024-06-21 08:20:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02/01/2024</td>\n",
       "      <td>A1ES34</td>\n",
       "      <td>BRA1ESBDR007</td>\n",
       "      <td>AES CORP</td>\n",
       "      <td>DRN</td>\n",
       "      <td>Registro</td>\n",
       "      <td>34.00</td>\n",
       "      <td>92.88</td>\n",
       "      <td>3158.08</td>\n",
       "      <td>567</td>\n",
       "      <td>2024-06-21 08:20:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Data_dt  Ticker          ISIN  \\\n",
       "0  02/01/2024  5GTK11  BR5GTKCTF000   \n",
       "1  02/01/2024  A1CR34  BRA1CRBDR003   \n",
       "2  02/01/2024  A1DM34  BRA1DMBDR002   \n",
       "3  02/01/2024  A1EP34  BRA1EPBDR003   \n",
       "4  02/01/2024  A1ES34  BRA1ESBDR007   \n",
       "\n",
       "                                  empresa_oufundo Tipo   Mercado  saldo_qte  \\\n",
       "0  IÍNNVDEICSET OIE ETF BLUESTAR 5G COM INDEX FDO   CI  Registro       1.00   \n",
       "1                                       AMCOR PLC  DRN  Registro      17.00   \n",
       "2                       ARCHER-DANIELS-MIDLAND CO  DRN  Registro     102.00   \n",
       "3                  AMERICAN ELECTRIC POWER CO INC  DRN  Registro       6.00   \n",
       "4                                        AES CORP  DRN  Registro      34.00   \n",
       "\n",
       "   preco_medio  saldo_volfin  doc_page         proc_datedt  \n",
       "0        81.82         81.82       567 2024-06-21 08:20:47  \n",
       "1        47.19        802.30       567 2024-06-21 08:20:47  \n",
       "2       354.03      36111.06       567 2024-06-21 08:20:47  \n",
       "3       195.27       1171.62       567 2024-06-21 08:20:47  \n",
       "4        92.88       3158.08       567 2024-06-21 08:20:47  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloaded_files = func_get_file_names(directory_path) #getting the files names downloaded\n",
    "df_append = pd.DataFrame() #init the final appended dataframe\n",
    "\n",
    "for file_name in downloaded_files: #loop over all .pdf daily bulletin manually downloaded from B3 website\n",
    "\n",
    "    pdf_path = os.path.join(directory_path, file_name) # creating the complete file path to the pdf document\n",
    "    print('\\n---------------------- Extracting from file: {} ----------------------\\n'.format(file_name))\n",
    "    \n",
    "    ################## 1 - Look over the .pdf file for the pages where the desire table begins and ends\n",
    "    \n",
    "    initial_page_tag = max(func_find_string_in_pdf(pdf_path, initial_tag)) # finding the initial page tag\n",
    "    final_page_tag = max(func_find_string_in_pdf(pdf_path, final_tag)) # finding the final page tag\n",
    "\n",
    "    print(f'The string \"{initial_tag}\" was last found on the following page: {initial_page_tag} \\n')\n",
    "    print(f'The string \"{final_tag}\" was last found on the following page: {final_page_tag} \\n')\n",
    "    print('\\n--------------- Step 1 completed ----------------\\n')\n",
    "\n",
    "    ################## 2 - Scrapping tables of data from the previous defined page range\n",
    "    df_data = func_btb_open_pos_extract_tables(pdf_path,\n",
    "                                initial_page_tag,\n",
    "                                final_page_tag,\n",
    "                                initial_word_tag,\n",
    "                                final_word_tag,\n",
    "                                table_columns)\n",
    "    print('\\n--------------- Step 2 completed ----------------\\n')\n",
    "\n",
    "    ################## 3  - Processing and cleaning dataframe\n",
    "    df_final = func_process_dataframe(df_data)\n",
    "    print('\\n--------------- Step 3 completed ----------------\\n')\n",
    "\n",
    "    #append daily dataframes scrapped into a final df\n",
    "    df_append = pd.concat([df_append,df_final], ignore_index = True)\n",
    "    \n",
    "    \n",
    "# Displaying dataframe appended\n",
    "print(df_append.info())\n",
    "df_append.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a8621",
   "metadata": {},
   "source": [
    "## Write the dataframe into a local SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91014351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1488"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('D:/finance_data/finance_database.db')\n",
    "\n",
    "df_final.to_sql('B3_securities_lending_open_pos',conn,if_exists='replace',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
